{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üõ∞Ô∏è EuroSAT Model Evaluation Demo\n",
        "\n",
        "## One-Click Comprehensive Model Comparison\n",
        "\n",
        "This notebook evaluates and compares the following models on the **EuroSAT** satellite image classification dataset:\n",
        "\n",
        "### Classical Machine Learning Models (Trained from scratch - Fast)\n",
        "- **K-NN** (K-Nearest Neighbors)\n",
        "- **Random Forest**\n",
        "- **SVM** (Support Vector Machine)\n",
        "\n",
        "### Deep Learning Models\n",
        "- **Simple CNN** (Trained from scratch - Fast)\n",
        "- **ConvNeXt-Tiny Frozen** (Pre-trained, loaded from file)\n",
        "- **ConvNeXt-Tiny Fine-tuned** (Pre-trained, loaded from file)\n",
        "- **ConvNeXt-Small Frozen** (Pre-trained, loaded from file)\n",
        "- **ConvNeXt-Small Fine-tuned** (Pre-trained, loaded from file)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Prerequisites\n",
        "Before running this notebook, ensure the following model files are uploaded to `/content/` in Google Colab:\n",
        "- `best_model_tiny_frozen.pth`\n",
        "- `best_model_tiny_finetuned.pth`\n",
        "- `best_model_small_frozen.pth`\n",
        "- `best_model_small_finetuned.pth`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Section 1: Setup & Installation"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install timm==0.6.13 --quiet\n",
        "\n",
        "# Clone ConvNeXt repository for model definitions\n",
        "import os\n",
        "if not os.path.exists('ConvNeXt'):\n",
        "    !git clone https://github.com/facebookresearch/ConvNeXt.git --quiet\n",
        "\n",
        "# Add ConvNeXt to path\n",
        "import sys\n",
        "sys.path.insert(0, 'ConvNeXt')\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "import ssl\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.datasets.utils import download_url\n",
        "import models.convnext as convnext\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"üöÄ Running on: {DEVICE}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "import_libraries"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Section 2: Download & Prepare EuroSAT Dataset"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "DATA_DIR = '/content/dataset'\n",
        "URL = \"https://madm.dfki.de/files/sentinel/EuroSAT.zip\"\n",
        "\n",
        "# Bypass SSL Certificate Check\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "print(f\"‚¨áÔ∏è Downloading EuroSAT dataset to {DATA_DIR}...\")\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    os.makedirs(DATA_DIR)\n",
        "\n",
        "# Download & Extract\n",
        "zip_path = os.path.join(DATA_DIR, 'EuroSAT.zip')\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    try:\n",
        "        download_url(URL, DATA_DIR, 'EuroSAT.zip', None)\n",
        "        print(\"‚úÖ Download successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Standard download failed: {e}\")\n",
        "        import requests\n",
        "        print(\"üîÑ Attempting fallback download...\")\n",
        "        r = requests.get(URL, verify=False)\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        print(\"‚úÖ Fallback download successful.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already downloaded.\")\n",
        "\n",
        "print(\"üìÇ Extracting...\")\n",
        "if not os.path.exists(os.path.join(DATA_DIR, 'train')):\n",
        "    shutil.unpack_archive(zip_path, DATA_DIR)\n",
        "\n",
        "    # Re-Organize into Train/Val\n",
        "    extracted_items = [f for f in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, f))]\n",
        "    source_root = os.path.join(DATA_DIR, extracted_items[0])\n",
        "\n",
        "    train_dir = os.path.join(DATA_DIR, 'train')\n",
        "    val_dir = os.path.join(DATA_DIR, 'val')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    print(\"üîÑ Splitting data into Train (80%) and Val (20%)...\")\n",
        "    classes = os.listdir(source_root)\n",
        "\n",
        "    for class_name in tqdm(classes, desc=\"Processing classes\"):\n",
        "        class_path = os.path.join(source_root, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "        split_point = int(len(images) * 0.8)\n",
        "\n",
        "        for img in images[:split_point]:\n",
        "            shutil.copy(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))\n",
        "        for img in images[split_point:]:\n",
        "            shutil.copy(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))\n",
        "\n",
        "    print(\"‚úÖ Dataset prepared successfully!\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already prepared.\")\n",
        "\n",
        "# Display dataset info\n",
        "train_classes = sorted(os.listdir(os.path.join(DATA_DIR, 'train')))\n",
        "print(f\"\\nüìä Dataset Statistics:\")\n",
        "print(f\"   Classes: {len(train_classes)}\")\n",
        "print(f\"   Class names: {train_classes}\")"
      ],
      "metadata": {
        "id": "download_eurosat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Section 3: Define Global Variables & Helper Functions"
      ],
      "metadata": {
        "id": "globals_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GLOBAL CONFIGURATION ---\n",
        "TRAIN_DIR = '/content/dataset/train'\n",
        "VAL_DIR = '/content/dataset/val'\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE_CLASSICAL = 64  # For classical ML models\n",
        "IMG_SIZE_DL = 224  # For deep learning models\n",
        "\n",
        "# Model file paths (uploaded to /content/)\n",
        "MODEL_PATHS = {\n",
        "    'tiny_frozen': '/content/best_model_tiny_frozen.pth',\n",
        "    'tiny_finetuned': '/content/best_model_tiny_finetuned.pth',\n",
        "    'small_frozen': '/content/best_model_small_frozen.pth',\n",
        "    'small_finetuned': '/content/best_model_small_finetuned.pth',\n",
        "    'simple_cnn': '/content/best_model_simple_cnn.pth'\n",
        "}\n",
        "\n",
        "# Store all results\n",
        "RESULTS = {}\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "\n",
        "def load_data_classical(data_dir, img_size=64):\n",
        "    \"\"\"Load and flatten images for classical ML models\"\"\"\n",
        "    print(f\"üìÇ Loading data from {data_dir}...\")\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(data_dir))\n",
        "\n",
        "    for label_idx, class_name in tqdm(enumerate(class_names), total=len(class_names), desc=\"Classes\"):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (img_size, img_size))\n",
        "                images.append(img.flatten())\n",
        "                labels.append(label_idx)\n",
        "    return np.array(images), np.array(labels), class_names\n",
        "\n",
        "\n",
        "def evaluate_pytorch_model(model, dataloader, device):\n",
        "    \"\"\"Evaluate a PyTorch model and return accuracy and predictions\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    confidences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            top_conf, preds = torch.max(probs, dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            confidences.extend(top_conf.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_confidence = np.mean(confidences) * 100\n",
        "    return accuracy, avg_confidence, all_preds, all_labels\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, title):\n",
        "    \"\"\"Plot confusion matrix\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"‚úÖ Helper functions defined!\")"
      ],
      "metadata": {
        "id": "helper_functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî¨ Section 4: Classical ML Models (K-NN, Random Forest, SVM)"
      ],
      "metadata": {
        "id": "classical_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üî¨ CLASSICAL MACHINE LEARNING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load data for classical models\n",
        "print(\"\\n--- Loading Data for Classical Models ---\")\n",
        "X_train, y_train, class_names = load_data_classical(TRAIN_DIR, IMG_SIZE_CLASSICAL)\n",
        "X_val, y_val, _ = load_data_classical(VAL_DIR, IMG_SIZE_CLASSICAL)\n",
        "print(f\"‚úÖ Data Loaded. Train shape: {X_train.shape}, Val shape: {X_val.shape}\")\n",
        "\n",
        "# Preprocessing with PCA\n",
        "print(\"\\n--- Preprocessing (PCA Dimensionality Reduction) ---\")\n",
        "print(\"‚öôÔ∏è Reducing dimensions from 12,288 -> 100 features...\")\n",
        "preprocessor = make_pipeline(StandardScaler(), PCA(n_components=100))\n",
        "X_train_reduced = preprocessor.fit_transform(X_train)\n",
        "X_val_reduced = preprocessor.transform(X_val)\n",
        "print(f\"‚úÖ Reduced shape: {X_train_reduced.shape}\")\n",
        "\n",
        "# Define classical models\n",
        "classical_models = [\n",
        "    (\"K-NN (k=5)\", KNeighborsClassifier(n_neighbors=5)),\n",
        "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
        "    (\"SVM (Linear)\", LinearSVC(dual='auto', max_iter=5000, random_state=42)),\n",
        "]\n",
        "\n",
        "print(\"\\n--- Training & Evaluating Classical Models ---\")\n",
        "classical_results = []\n",
        "\n",
        "for name, model in classical_models:\n",
        "    print(f\"\\nüîÑ Training {name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.fit(X_train_reduced, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_val_reduced)\n",
        "    accuracy = accuracy_score(y_val, y_pred) * 100\n",
        "\n",
        "    RESULTS[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'train_time': train_time,\n",
        "        'y_pred': y_pred,\n",
        "        'y_true': y_val\n",
        "    }\n",
        "\n",
        "    print(f\"   ‚úÖ {name}: Accuracy = {accuracy:.2f}% (Training time: {train_time:.2f}s)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Classical ML Models Complete!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "classical_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Section 5: Simple CNN (Train from Scratch)"
      ],
      "metadata": {
        "id": "simple_cnn_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üß† SIMPLE CNN (Training from Scratch)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define Simple CNN Architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # 64 -> 32\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # 32 -> 16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)   # 16 -> 8\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 8 * 8, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Data Setup for Simple CNN (64x64 resolution)\n",
        "transform_cnn = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset_cnn = datasets.ImageFolder(TRAIN_DIR, transform_cnn)\n",
        "val_dataset_cnn = datasets.ImageFolder(VAL_DIR, transform_cnn)\n",
        "train_loader_cnn = DataLoader(train_dataset_cnn, batch_size=64, shuffle=True)\n",
        "val_loader_cnn = DataLoader(val_dataset_cnn, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "simple_cnn = SimpleCNN().to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(simple_cnn.parameters(), lr=1e-3)\n",
        "\n",
        "# Training Loop\n",
        "EPOCHS_CNN = 10\n",
        "best_acc = 0.0\n",
        "\n",
        "print(f\"\\nüî• Training Simple CNN for {EPOCHS_CNN} epochs...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS_CNN):\n",
        "    simple_cnn.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader_cnn, desc=f\"Epoch {epoch+1}/{EPOCHS_CNN}\", leave=False):\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = simple_cnn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    simple_cnn.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader_cnn:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = simple_cnn(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_acc = 100 * correct / total\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        torch.save(simple_cnn.state_dict(), MODEL_PATHS['simple_cnn'])\n",
        "\n",
        "    print(f\"   Epoch {epoch+1}: Loss={running_loss/len(train_loader_cnn):.4f}, Val Acc={epoch_acc:.2f}%\")\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "# Final Evaluation\n",
        "simple_cnn.load_state_dict(torch.load(MODEL_PATHS['simple_cnn']))\n",
        "acc, conf, preds, labels = evaluate_pytorch_model(simple_cnn, val_loader_cnn, DEVICE)\n",
        "\n",
        "RESULTS['Simple CNN'] = {\n",
        "    'accuracy': acc,\n",
        "    'confidence': conf,\n",
        "    'train_time': train_time,\n",
        "    'y_pred': preds,\n",
        "    'y_true': labels\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Simple CNN: Best Accuracy = {best_acc:.2f}% (Training time: {train_time:.2f}s)\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "simple_cnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî• Section 6: ConvNeXt Models (Load Pre-trained Weights)"
      ],
      "metadata": {
        "id": "convnext_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üî• CONVNEXT MODELS (Loading Pre-trained Weights)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Data Setup for ConvNeXt (224x224 resolution)\n",
        "transform_convnext = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_dataset_convnext = datasets.ImageFolder(VAL_DIR, transform_convnext)\n",
        "val_loader_convnext = DataLoader(val_dataset_convnext, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ConvNeXt Model configurations\n",
        "convnext_configs = [\n",
        "    (\"ConvNeXt-Tiny (Frozen)\", \"tiny\", MODEL_PATHS['tiny_frozen']),\n",
        "    (\"ConvNeXt-Tiny (Fine-tuned)\", \"tiny\", MODEL_PATHS['tiny_finetuned']),\n",
        "    (\"ConvNeXt-Small (Frozen)\", \"small\", MODEL_PATHS['small_frozen']),\n",
        "    (\"ConvNeXt-Small (Fine-tuned)\", \"small\", MODEL_PATHS['small_finetuned']),\n",
        "]\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Checking for model files...\")\n",
        "for name, arch, path in convnext_configs:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"   ‚úÖ Found: {path}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Missing: {path}\")\n",
        "\n",
        "print(\"\\n--- Evaluating ConvNeXt Models ---\")\n",
        "\n",
        "for name, arch_type, model_path in convnext_configs:\n",
        "    print(f\"\\nüîÑ Loading {name}...\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"   ‚ùå Skipping: Model file not found at {model_path}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Initialize architecture\n",
        "        if arch_type == \"tiny\":\n",
        "            model = convnext.convnext_tiny(pretrained=False)\n",
        "        else:\n",
        "            model = convnext.convnext_small(pretrained=False)\n",
        "\n",
        "        # Modify head for 10 classes\n",
        "        n_inputs = model.head.in_features\n",
        "        model.head = nn.Linear(n_inputs, NUM_CLASSES)\n",
        "\n",
        "        # Load weights\n",
        "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "        model.to(DEVICE)\n",
        "        model.eval()\n",
        "        print(f\"   ‚úÖ Weights loaded successfully!\")\n",
        "\n",
        "        # Evaluate\n",
        "        acc, conf, preds, labels = evaluate_pytorch_model(model, val_loader_convnext, DEVICE)\n",
        "\n",
        "        RESULTS[name] = {\n",
        "            'accuracy': acc,\n",
        "            'confidence': conf,\n",
        "            'y_pred': preds,\n",
        "            'y_true': labels\n",
        "        }\n",
        "\n",
        "        print(f\"   üìä {name}: Accuracy = {acc:.2f}%, Confidence = {conf:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error loading {name}: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ConvNeXt Models Evaluation Complete!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "convnext_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Section 7: Results Summary & Comparison"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üìä COMPREHENSIVE RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create summary table\n",
        "print(\"\\n{:<35} {:>15} {:>15}\".format(\"Model\", \"Accuracy (%)\", \"Type\"))\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Sort results by accuracy\n",
        "sorted_results = sorted(RESULTS.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
        "\n",
        "for name, data in sorted_results:\n",
        "    model_type = \"Classical ML\" if name in [\"K-NN (k=5)\", \"Random Forest\", \"SVM (Linear)\"] else \"Deep Learning\"\n",
        "    print(\"{:<35} {:>15.2f} {:>15}\".format(name, data['accuracy'], model_type))\n",
        "\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Best model\n",
        "best_model = sorted_results[0]\n",
        "print(f\"\\nüèÜ Best Model: {best_model[0]} with {best_model[1]['accuracy']:.2f}% accuracy\")"
      ],
      "metadata": {
        "id": "results_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Bar Chart Comparison\n",
        "print(\"\\nüìà Accuracy Comparison Chart\")\n",
        "\n",
        "model_names = [name for name, _ in sorted_results]\n",
        "accuracies = [data['accuracy'] for _, data in sorted_results]\n",
        "\n",
        "# Color coding\n",
        "colors = []\n",
        "for name in model_names:\n",
        "    if name in [\"K-NN (k=5)\", \"Random Forest\", \"SVM (Linear)\"]:\n",
        "        colors.append('#3498db')  # Blue for classical\n",
        "    elif name == \"Simple CNN\":\n",
        "        colors.append('#2ecc71')  # Green for simple CNN\n",
        "    elif \"Frozen\" in name:\n",
        "        colors.append('#f39c12')  # Orange for frozen\n",
        "    else:\n",
        "        colors.append('#e74c3c')  # Red for fine-tuned\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "bars = plt.barh(model_names[::-1], accuracies[::-1], color=colors[::-1])\n",
        "plt.xlabel('Accuracy (%)', fontsize=12)\n",
        "plt.title('EuroSAT Model Comparison', fontsize=14, fontweight='bold')\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "# Add value labels\n",
        "for bar, acc in zip(bars, accuracies[::-1]):\n",
        "    plt.text(acc + 1, bar.get_y() + bar.get_height()/2, f'{acc:.1f}%',\n",
        "             va='center', fontsize=10)\n",
        "\n",
        "# Legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#3498db', label='Classical ML'),\n",
        "    Patch(facecolor='#2ecc71', label='Simple CNN'),\n",
        "    Patch(facecolor='#f39c12', label='ConvNeXt Frozen'),\n",
        "    Patch(facecolor='#e74c3c', label='ConvNeXt Fine-tuned')\n",
        "]\n",
        "plt.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Chart saved to /content/model_comparison.png\")"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Section 8: Confusion Matrices for All Models"
      ],
      "metadata": {
        "id": "confusion_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üîç CONFUSION MATRICES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get class names\n",
        "class_names = sorted(os.listdir(VAL_DIR))\n",
        "\n",
        "# Plot confusion matrices for all models\n",
        "for name, data in RESULTS.items():\n",
        "    if 'y_pred' in data and 'y_true' in data:\n",
        "        print(f\"\\nüìä {name}\")\n",
        "        plot_confusion_matrix(data['y_true'], data['y_pred'], class_names, f'Confusion Matrix: {name}')"
      ],
      "metadata": {
        "id": "confusion_matrices"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìã Section 9: Detailed Classification Reports"
      ],
      "metadata": {
        "id": "reports_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìã DETAILED CLASSIFICATION REPORTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, data in sorted_results[:3]:  # Top 3 models\n",
        "    if 'y_pred' in data and 'y_true' in data:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üìä {name}\")\n",
        "        print(\"=\"*60)\n",
        "        print(classification_report(data['y_true'], data['y_pred'], target_names=class_names))"
      ],
      "metadata": {
        "id": "classification_reports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Section 10: Final Summary"
      ],
      "metadata": {
        "id": "final_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéØ FINAL EVALUATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìä Model Performance Ranking:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for i, (name, data) in enumerate(sorted_results, 1):\n",
        "    medal = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else \"  \"\n",
        "    print(f\"{medal} {i}. {name}: {data['accuracy']:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"\\nüìù Key Observations:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Calculate improvements\n",
        "classical_best = max([data['accuracy'] for name, data in RESULTS.items()\n",
        "                      if name in [\"K-NN (k=5)\", \"Random Forest\", \"SVM (Linear)\"]])\n",
        "\n",
        "dl_best = max([data['accuracy'] for name, data in RESULTS.items()\n",
        "               if name not in [\"K-NN (k=5)\", \"Random Forest\", \"SVM (Linear)\"]], default=0)\n",
        "\n",
        "print(f\"\\n1. Best Classical ML Accuracy: {classical_best:.2f}%\")\n",
        "print(f\"2. Best Deep Learning Accuracy: {dl_best:.2f}%\")\n",
        "if dl_best > 0:\n",
        "    print(f\"3. Deep Learning Improvement: +{dl_best - classical_best:.2f}%\")\n",
        "\n",
        "# Fine-tuning vs Frozen comparison\n",
        "frozen_models = {name: data for name, data in RESULTS.items() if \"Frozen\" in name}\n",
        "finetuned_models = {name: data for name, data in RESULTS.items() if \"Fine-tuned\" in name}\n",
        "\n",
        "if frozen_models and finetuned_models:\n",
        "    frozen_avg = np.mean([data['accuracy'] for data in frozen_models.values()])\n",
        "    finetuned_avg = np.mean([data['accuracy'] for data in finetuned_models.values()])\n",
        "    print(f\"\\n4. Average Frozen Model Accuracy: {frozen_avg:.2f}%\")\n",
        "    print(f\"5. Average Fine-tuned Model Accuracy: {finetuned_avg:.2f}%\")\n",
        "    print(f\"6. Fine-tuning Improvement: +{finetuned_avg - frozen_avg:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "final_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üå™Ô∏è NOISE ROBUSTNESS TEST (Deep Learning Models)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Configuration\n",
        "NOISE_LEVELS = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "VAL_DIR = '/content/dataset/val'\n",
        "\n",
        "# Base transform (without noise)\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(VAL_DIR, base_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Helper function to add Gaussian noise\n",
        "def add_gaussian_noise(tensor, noise_factor):\n",
        "    \"\"\"Add Gaussian noise to tensor\"\"\"\n",
        "    if noise_factor == 0:\n",
        "        return tensor\n",
        "    noise = torch.randn_like(tensor) * noise_factor\n",
        "    return tensor + noise\n",
        "\n",
        "# Helper function to evaluate with noise\n",
        "def evaluate_with_noise(model, dataloader, device, noise_factor):\n",
        "    \"\"\"Evaluate model with added Gaussian noise\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            # Add noise to inputs\n",
        "            inputs = add_gaussian_noise(inputs, noise_factor)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Define deep learning models to test\n",
        "dl_model_configs = [\n",
        "    (\"Simple CNN\", \"simple_cnn\", '/content/best_model_simple_cnn.pth', \"simple_cnn\"),\n",
        "    (\"Tiny (Frozen)\", \"tiny\", '/content/best_model_tiny_frozen.pth', \"convnext\"),\n",
        "    (\"Tiny (Fine-Tuned)\", \"tiny\", '/content/best_model_tiny_finetuned.pth', \"convnext\"),\n",
        "    (\"Small (Frozen)\", \"small\", '/content/best_model_small_frozen.pth', \"convnext\"),\n",
        "    (\"Small (Fine-Tuned)\", \"small\", '/content/best_model_small_finetuned.pth', \"convnext\"),\n",
        "]\n",
        "\n",
        "# Store results\n",
        "noise_results = {}\n",
        "\n",
        "print(f\"\\nüìä Testing {len(dl_model_configs)} models across {len(NOISE_LEVELS)} noise levels...\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for model_name, arch_type, model_path, model_type in dl_model_configs:\n",
        "    print(f\"\\nüîÑ Testing: {model_name}\")\n",
        "\n",
        "    # Check if model file exists\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"   ‚ùå Skipping: Model file not found at {model_path}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Initialize model architecture\n",
        "        if model_type == \"simple_cnn\":\n",
        "            # Simple CNN architecture (must match the trained model)\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "                    self.features = nn.Sequential(\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                    )\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Flatten(),\n",
        "                        nn.Linear(128 * 8 * 8, 256),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.5),\n",
        "                        nn.Linear(256, 10)\n",
        "                    )\n",
        "                def forward(self, x):\n",
        "                    x = self.features(x)\n",
        "                    x = self.classifier(x)\n",
        "                    return x\n",
        "\n",
        "            model = SimpleCNN()\n",
        "            # Simple CNN uses 64x64, need different dataloader\n",
        "            transform_64 = transforms.Compose([\n",
        "                transforms.Resize((64, 64)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            dataset_64 = datasets.ImageFolder(VAL_DIR, transform_64)\n",
        "            test_dataloader = DataLoader(dataset_64, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        else:\n",
        "            # ConvNeXt models\n",
        "            if arch_type == \"tiny\":\n",
        "                model = convnext.convnext_tiny(pretrained=False)\n",
        "            else:\n",
        "                model = convnext.convnext_small(pretrained=False)\n",
        "\n",
        "            n_inputs = model.head.in_features\n",
        "            model.head = nn.Linear(n_inputs, 10)\n",
        "            test_dataloader = dataloader\n",
        "\n",
        "        # Load weights\n",
        "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "        model.to(DEVICE)\n",
        "        model.eval()\n",
        "\n",
        "        # Test across noise levels\n",
        "        accuracies = []\n",
        "        for noise in tqdm(NOISE_LEVELS, desc=f\"   üìä {model_name}\", unit=\"level\"):\n",
        "            acc = evaluate_with_noise(model, test_dataloader, DEVICE, noise)\n",
        "            accuracies.append(acc)\n",
        "\n",
        "        noise_results[model_name] = accuracies\n",
        "        print(f\"   ‚úÖ Results: {[f'{a:.1f}%' for a in accuracies]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# üìà PLOT: Robustness Analysis Graph\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìà GENERATING ROBUSTNESS ANALYSIS GRAPH\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Define colors and styles for each model type\n",
        "style_config = {\n",
        "    \"Simple CNN\": {\"color\": \"#2ecc71\", \"linestyle\": \"-\", \"marker\": \"s\", \"linewidth\": 2.5},\n",
        "    \"Tiny (Frozen)\": {\"color\": \"#0066CC\", \"linestyle\": \"-\", \"marker\": \"o\", \"linewidth\": 2.5},\n",
        "    \"Tiny (Fine-Tuned)\": {\"color\": \"#00FFFF\", \"linestyle\": \"-\", \"marker\": \"o\", \"linewidth\": 2.5},\n",
        "    \"Small (Frozen)\": {\"color\": \"#FF0000\", \"linestyle\": \"--\", \"marker\": \"o\", \"linewidth\": 2.5},\n",
        "    \"Small (Fine-Tuned)\": {\"color\": \"#FFA500\", \"linestyle\": \"--\", \"marker\": \"o\", \"linewidth\": 2.5},\n",
        "}\n",
        "\n",
        "# Plot each model\n",
        "for model_name, accuracies in noise_results.items():\n",
        "    style = style_config.get(model_name, {\"color\": \"gray\", \"linestyle\": \"-\", \"marker\": \"x\", \"linewidth\": 2})\n",
        "    plt.plot(NOISE_LEVELS, accuracies,\n",
        "             color=style[\"color\"],\n",
        "             linestyle=style[\"linestyle\"],\n",
        "             marker=style[\"marker\"],\n",
        "             linewidth=style[\"linewidth\"],\n",
        "             markersize=8,\n",
        "             label=model_name)\n",
        "\n",
        "plt.xlabel('Noise Factor (œÉ)', fontsize=14)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.title('Robustness Analysis: Model Brittleness Under Noise', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc='upper right', fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(-0.02, 0.42)\n",
        "plt.ylim(0, 105)\n",
        "\n",
        "# Add annotations for key observations\n",
        "plt.axhline(y=50, color='gray', linestyle=':', alpha=0.5, label='_nolegend_')\n",
        "plt.text(0.35, 52, 'Random Guess (10 classes)', fontsize=9, color='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/noise_robustness_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Graph saved to /content/noise_robustness_analysis.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# üìä DETAILED RESULTS TABLE\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä NOISE ROBUSTNESS RESULTS TABLE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Print header\n",
        "header = \"{:<25}\".format(\"Model\")\n",
        "for noise in NOISE_LEVELS:\n",
        "    header += \"{:>12}\".format(f\"œÉ={noise}\")\n",
        "header += \"{:>15}\".format(\"Drop (0‚Üí0.4)\")\n",
        "print(header)\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Print results for each model\n",
        "for model_name, accuracies in noise_results.items():\n",
        "    row = \"{:<25}\".format(model_name)\n",
        "    for acc in accuracies:\n",
        "        row += \"{:>12}\".format(f\"{acc:.2f}%\")\n",
        "    # Calculate accuracy drop\n",
        "    drop = accuracies[0] - accuracies[-1]\n",
        "    row += \"{:>15}\".format(f\"-{drop:.2f}%\")\n",
        "    print(row)\n",
        "\n",
        "print(\"-\"*100)\n",
        "\n",
        "# =============================================================================\n",
        "# üîç KEY OBSERVATIONS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîç KEY OBSERVATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if noise_results:\n",
        "    # Find most robust model (smallest drop)\n",
        "    drops = {name: accs[0] - accs[-1] for name, accs in noise_results.items()}\n",
        "    most_robust = min(drops, key=drops.get)\n",
        "    least_robust = max(drops, key=drops.get)\n",
        "\n",
        "    print(f\"\\n1. üèÜ Most Robust Model: {most_robust}\")\n",
        "    print(f\"   - Accuracy drop: {drops[most_robust]:.2f}% (from œÉ=0 to œÉ=0.4)\")\n",
        "\n",
        "    print(f\"\\n2. ‚ö†Ô∏è  Least Robust Model: {least_robust}\")\n",
        "    print(f\"   - Accuracy drop: {drops[least_robust]:.2f}% (from œÉ=0 to œÉ=0.4)\")\n",
        "\n",
        "    # Compare frozen vs fine-tuned\n",
        "    frozen_drops = [v for k, v in drops.items() if \"Frozen\" in k]\n",
        "    finetuned_drops = [v for k, v in drops.items() if \"Fine-Tuned\" in k]\n",
        "\n",
        "    if frozen_drops and finetuned_drops:\n",
        "        avg_frozen_drop = np.mean(frozen_drops)\n",
        "        avg_finetuned_drop = np.mean(finetuned_drops)\n",
        "        print(f\"\\n3. üìä Frozen vs Fine-Tuned Comparison:\")\n",
        "        print(f\"   - Avg. Frozen model drop: {avg_frozen_drop:.2f}%\")\n",
        "        print(f\"   - Avg. Fine-Tuned model drop: {avg_finetuned_drop:.2f}%\")\n",
        "\n",
        "        if avg_frozen_drop < avg_finetuned_drop:\n",
        "            print(f\"   - ‚úÖ Frozen models are MORE robust to noise\")\n",
        "        else:\n",
        "            print(f\"   - ‚úÖ Fine-Tuned models are MORE robust to noise\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ NOISE ROBUSTNESS TEST COMPLETE!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "2MoedRkO9nHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üå™Ô∏è NOISE ROBUSTNESS TEST - CLASSICAL BASELINE MODELS (K-NN, RF, SVM)\n",
        "# =============================================================================\n",
        "# This cell tests how classical ML models perform under different levels of\n",
        "# Gaussian noise, enabling fair comparison with deep learning models.\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üå™Ô∏è NOISE ROBUSTNESS TEST (Classical Baseline Models)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Configuration\n",
        "NOISE_LEVELS = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
        "VAL_DIR = '/content/dataset/val'\n",
        "TRAIN_DIR = '/content/dataset/train'\n",
        "IMG_SIZE = 64\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function: Load Data with Noise\n",
        "# =============================================================================\n",
        "def load_data_with_noise(data_dir, img_size=64, noise_factor=0.0):\n",
        "    \"\"\"Load and flatten images with added Gaussian noise for classical ML\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(data_dir))\n",
        "\n",
        "    for label_idx, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (img_size, img_size))\n",
        "                # Normalize to 0-1, add noise, clip back\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "                if noise_factor > 0:\n",
        "                    noise = np.random.randn(*img.shape) * noise_factor\n",
        "                    img = np.clip(img + noise, 0, 1)\n",
        "                img = (img * 255).astype(np.uint8)\n",
        "                images.append(img.flatten())\n",
        "                labels.append(label_idx)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# =============================================================================\n",
        "# Step 1: Load Clean Training Data & Train Models\n",
        "# =============================================================================\n",
        "print(\"\\nüìÇ Loading clean training data...\")\n",
        "X_train_clean, y_train = load_data_with_noise(TRAIN_DIR, IMG_SIZE, noise_factor=0.0)\n",
        "print(f\"   ‚úÖ Training data shape: {X_train_clean.shape}\")\n",
        "\n",
        "# Fit preprocessor on clean data\n",
        "print(\"\\n‚öôÔ∏è Fitting PCA preprocessor (12,288 ‚Üí 100 features)...\")\n",
        "preprocessor = make_pipeline(StandardScaler(), PCA(n_components=100))\n",
        "X_train_reduced = preprocessor.fit_transform(X_train_clean)\n",
        "\n",
        "# Train classical models on clean data\n",
        "print(\"\\nüîÑ Training classical models on clean data...\")\n",
        "classical_models = {\n",
        "    \"K-NN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    \"SVM\": LinearSVC(dual='auto', max_iter=5000, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in classical_models.items():\n",
        "    model.fit(X_train_reduced, y_train)\n",
        "    print(f\"   ‚úÖ {name} trained\")\n",
        "\n",
        "# =============================================================================\n",
        "# Step 2: Test Models Across Noise Levels\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"üß™ Testing classical models across noise levels...\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "classical_noise_results = {name: [] for name in classical_models.keys()}\n",
        "\n",
        "for noise in tqdm(NOISE_LEVELS, desc=\"üìä Noise Levels\"):\n",
        "    # Load validation data with noise\n",
        "    X_val_noisy, y_val = load_data_with_noise(VAL_DIR, IMG_SIZE, noise_factor=noise)\n",
        "    X_val_reduced = preprocessor.transform(X_val_noisy)\n",
        "\n",
        "    for name, model in classical_models.items():\n",
        "        y_pred = model.predict(X_val_reduced)\n",
        "        acc = accuracy_score(y_val, y_pred) * 100\n",
        "        classical_noise_results[name].append(acc)\n",
        "\n",
        "# =============================================================================\n",
        "# Step 3: Display Results Table\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä CLASSICAL MODELS - NOISE ROBUSTNESS RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Print header\n",
        "header = \"{:<20}\".format(\"Model\")\n",
        "for noise in NOISE_LEVELS:\n",
        "    header += \"{:>12}\".format(f\"œÉ={noise}\")\n",
        "header += \"{:>15}\".format(\"Drop (0‚Üí0.4)\")\n",
        "print(header)\n",
        "print(\"-\"*95)\n",
        "\n",
        "# Print results\n",
        "for name, accs in classical_noise_results.items():\n",
        "    row = \"{:<20}\".format(name)\n",
        "    for acc in accs:\n",
        "        row += \"{:>12}\".format(f\"{acc:.2f}%\")\n",
        "    drop = accs[0] - accs[-1]\n",
        "    row += \"{:>15}\".format(f\"-{drop:.2f}%\")\n",
        "    print(row)\n",
        "\n",
        "print(\"-\"*95)\n",
        "\n",
        "# =============================================================================\n",
        "# Step 4: Plot Classical Models Noise Robustness\n",
        "# =============================================================================\n",
        "print(\"\\nüìà Generating Classical Models Robustness Graph...\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Define colors and styles\n",
        "style_config = {\n",
        "    \"K-NN\": {\"color\": \"#9b59b6\", \"linestyle\": \"-\", \"marker\": \"^\"},\n",
        "    \"Random Forest\": {\"color\": \"#27ae60\", \"linestyle\": \"-\", \"marker\": \"s\"},\n",
        "    \"SVM\": {\"color\": \"#e67e22\", \"linestyle\": \"-\", \"marker\": \"d\"},\n",
        "}\n",
        "\n",
        "for name, accs in classical_noise_results.items():\n",
        "    style = style_config[name]\n",
        "    plt.plot(NOISE_LEVELS, accs,\n",
        "             color=style[\"color\"],\n",
        "             linestyle=style[\"linestyle\"],\n",
        "             marker=style[\"marker\"],\n",
        "             linewidth=2.5,\n",
        "             markersize=8,\n",
        "             label=name)\n",
        "\n",
        "plt.xlabel('Noise Factor (œÉ)', fontsize=14)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.title('Noise Robustness: Classical ML Models', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc='upper right', fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(-0.02, 0.42)\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/noise_robustness_classical.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Graph saved to /content/noise_robustness_classical.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# Step 5: Store Results for Combined Comparison\n",
        "# =============================================================================\n",
        "# Save results to global variable for combined plotting\n",
        "CLASSICAL_NOISE_RESULTS = classical_noise_results.copy()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ CLASSICAL MODELS NOISE TEST COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Quick comparison\n",
        "print(\"\\nüîç Quick Analysis:\")\n",
        "drops = {name: accs[0] - accs[-1] for name, accs in classical_noise_results.items()}\n",
        "most_robust = min(drops, key=drops.get)\n",
        "least_robust = max(drops, key=drops.get)\n",
        "print(f\"   üèÜ Most Robust: {most_robust} (drop: {drops[most_robust]:.2f}%)\")\n",
        "print(f\"   ‚ö†Ô∏è  Least Robust: {least_robust} (drop: {drops[least_robust]:.2f}%)\")"
      ],
      "metadata": {
        "id": "wrcZ_0ke9sSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üìä COMBINED NOISE ROBUSTNESS COMPARISON (All Models)\n",
        "# =============================================================================\n",
        "# This cell creates a combined visualization comparing noise robustness\n",
        "# of ALL models: Classical ML (K-NN, RF, SVM) vs Deep Learning (CNN, ConvNeXt)\n",
        "#\n",
        "# ‚ö†Ô∏è RUN THIS AFTER: Classical baseline noise test AND Deep learning noise test\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä COMBINED NOISE ROBUSTNESS COMPARISON\")\n",
        "print(\"   Classical ML vs Deep Learning Models\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Noise levels (must match previous cells)\n",
        "NOISE_LEVELS = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
        "\n",
        "# =============================================================================\n",
        "# Collect Results from Previous Cells\n",
        "# =============================================================================\n",
        "# Note: These variables should exist from running previous noise test cells\n",
        "# - CLASSICAL_NOISE_RESULTS: from classical baseline noise test\n",
        "# - noise_results: from deep learning noise test\n",
        "\n",
        "# Check if results exist\n",
        "try:\n",
        "    all_results = {}\n",
        "\n",
        "    # Add classical results\n",
        "    if 'CLASSICAL_NOISE_RESULTS' in dir():\n",
        "        all_results.update(CLASSICAL_NOISE_RESULTS)\n",
        "        print(\"‚úÖ Classical model results loaded\")\n",
        "    elif 'classical_noise_results' in dir():\n",
        "        all_results.update(classical_noise_results)\n",
        "        print(\"‚úÖ Classical model results loaded\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Classical results not found - run classical noise test first!\")\n",
        "\n",
        "    # Add deep learning results\n",
        "    if 'noise_results' in dir():\n",
        "        all_results.update(noise_results)\n",
        "        print(\"‚úÖ Deep learning model results loaded\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Deep learning results not found - run DL noise test first!\")\n",
        "\n",
        "    print(f\"\\nüìä Total models to compare: {len(all_results)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading results: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# Combined Visualization\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"üìà Generating Combined Robustness Comparison Graph...\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 9))\n",
        "\n",
        "# Define colors and styles for ALL models\n",
        "style_config = {\n",
        "    # Classical ML (solid lines, different markers)\n",
        "    \"K-NN\": {\"color\": \"#9b59b6\", \"linestyle\": \"-\", \"marker\": \"^\", \"linewidth\": 2.5, \"group\": \"Classical\"},\n",
        "    \"Random Forest\": {\"color\": \"#27ae60\", \"linestyle\": \"-\", \"marker\": \"s\", \"linewidth\": 2.5, \"group\": \"Classical\"},\n",
        "    \"SVM\": {\"color\": \"#1abc9c\", \"linestyle\": \"-\", \"marker\": \"d\", \"linewidth\": 2.5, \"group\": \"Classical\"},\n",
        "\n",
        "    # Simple CNN\n",
        "    \"Simple CNN\": {\"color\": \"#34495e\", \"linestyle\": \"-\", \"marker\": \"p\", \"linewidth\": 2.5, \"group\": \"Simple DL\"},\n",
        "\n",
        "    # ConvNeXt Frozen (dashed lines)\n",
        "    \"Tiny (Frozen)\": {\"color\": \"#0066CC\", \"linestyle\": \"--\", \"marker\": \"o\", \"linewidth\": 2.5, \"group\": \"ConvNeXt\"},\n",
        "    \"Small (Frozen)\": {\"color\": \"#FF0000\", \"linestyle\": \"--\", \"marker\": \"o\", \"linewidth\": 2.5, \"group\": \"ConvNeXt\"},\n",
        "\n",
        "    # ConvNeXt Fine-Tuned (solid lines)\n",
        "    \"Tiny (Fine-Tuned)\": {\"color\": \"#00CCFF\", \"linestyle\": \"-\", \"marker\": \"o\", \"linewidth\": 2.5, \"group\": \"ConvNeXt\"},\n",
        "    \"Small (Fine-Tuned)\": {\"color\": \"#FFA500\", \"linestyle\": \"-\", \"marker\": \"o\", \"linewidth\": 2.5, \"group\": \"ConvNeXt\"},\n",
        "}\n",
        "\n",
        "# Plot each model\n",
        "for model_name, accuracies in all_results.items():\n",
        "    if model_name in style_config:\n",
        "        style = style_config[model_name]\n",
        "    else:\n",
        "        # Default style for unknown models\n",
        "        style = {\"color\": \"gray\", \"linestyle\": \"-\", \"marker\": \"x\", \"linewidth\": 2}\n",
        "\n",
        "    ax.plot(NOISE_LEVELS, accuracies,\n",
        "            color=style[\"color\"],\n",
        "            linestyle=style[\"linestyle\"],\n",
        "            marker=style[\"marker\"],\n",
        "            linewidth=style[\"linewidth\"],\n",
        "            markersize=9,\n",
        "            label=model_name)\n",
        "\n",
        "ax.set_xlabel('Noise Factor (œÉ)', fontsize=14)\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
        "ax.set_title('Noise Robustness Comparison: Classical ML vs Deep Learning',\n",
        "             fontsize=16, fontweight='bold')\n",
        "ax.legend(loc='upper right', fontsize=10, ncol=2)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim(-0.02, 0.42)\n",
        "ax.set_ylim(0, 105)\n",
        "\n",
        "# Add reference line\n",
        "ax.axhline(y=10, color='gray', linestyle=':', alpha=0.5)\n",
        "ax.text(0.35, 12, 'Random Guess', fontsize=9, color='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/noise_robustness_all_models.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Combined graph saved to /content/noise_robustness_all_models.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# Comprehensive Results Table\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä COMPREHENSIVE NOISE ROBUSTNESS TABLE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Sort by accuracy at œÉ=0 (clean data)\n",
        "sorted_results = sorted(all_results.items(), key=lambda x: x[1][0], reverse=True)\n",
        "\n",
        "# Print header\n",
        "header = \"{:<25}\".format(\"Model\")\n",
        "for noise in NOISE_LEVELS:\n",
        "    header += \"{:>10}\".format(f\"œÉ={noise}\")\n",
        "header += \"{:>12}\".format(\"Drop\")\n",
        "header += \"{:>10}\".format(\"Type\")\n",
        "print(header)\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Determine model type\n",
        "def get_model_type(name):\n",
        "    if name in [\"K-NN\", \"Random Forest\", \"SVM\"]:\n",
        "        return \"Classical\"\n",
        "    elif name == \"Simple CNN\":\n",
        "        return \"CNN\"\n",
        "    else:\n",
        "        return \"ConvNeXt\"\n",
        "\n",
        "# Print results\n",
        "for name, accs in sorted_results:\n",
        "    row = \"{:<25}\".format(name)\n",
        "    for acc in accs:\n",
        "        row += \"{:>10}\".format(f\"{acc:.1f}%\")\n",
        "    drop = accs[0] - accs[-1]\n",
        "    row += \"{:>12}\".format(f\"-{drop:.1f}%\")\n",
        "    row += \"{:>10}\".format(get_model_type(name))\n",
        "    print(row)\n",
        "\n",
        "print(\"-\"*100)\n",
        "\n",
        "# =============================================================================\n",
        "# Key Insights\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîç KEY INSIGHTS: Classical vs Deep Learning Robustness\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate statistics\n",
        "classical_models = [\"K-NN\", \"Random Forest\", \"SVM\"]\n",
        "dl_models = [k for k in all_results.keys() if k not in classical_models]\n",
        "\n",
        "classical_drops = [all_results[m][0] - all_results[m][-1] for m in classical_models if m in all_results]\n",
        "dl_drops = [all_results[m][0] - all_results[m][-1] for m in dl_models if m in all_results]\n",
        "\n",
        "if classical_drops:\n",
        "    avg_classical_drop = np.mean(classical_drops)\n",
        "    print(f\"\\nüìä Classical ML Models:\")\n",
        "    print(f\"   - Average accuracy drop (œÉ=0 ‚Üí œÉ=0.4): {avg_classical_drop:.2f}%\")\n",
        "    print(f\"   - Most robust: {classical_models[np.argmin(classical_drops)]}\")\n",
        "\n",
        "if dl_drops:\n",
        "    avg_dl_drop = np.mean(dl_drops)\n",
        "    print(f\"\\nüß† Deep Learning Models:\")\n",
        "    print(f\"   - Average accuracy drop (œÉ=0 ‚Üí œÉ=0.4): {avg_dl_drop:.2f}%\")\n",
        "    most_robust_dl = dl_models[np.argmin(dl_drops)] if dl_drops else \"N/A\"\n",
        "    least_robust_dl = dl_models[np.argmax(dl_drops)] if dl_drops else \"N/A\"\n",
        "    print(f\"   - Most robust: {most_robust_dl}\")\n",
        "    print(f\"   - Least robust: {least_robust_dl}\")\n",
        "\n",
        "if classical_drops and dl_drops:\n",
        "    print(f\"\\n‚öñÔ∏è Comparison:\")\n",
        "    if avg_classical_drop < avg_dl_drop:\n",
        "        print(f\"   ‚úÖ Classical models are MORE robust to noise!\")\n",
        "        print(f\"   - Classical avg drop: {avg_classical_drop:.2f}%\")\n",
        "        print(f\"   - Deep Learning avg drop: {avg_dl_drop:.2f}%\")\n",
        "        print(f\"   - Difference: {avg_dl_drop - avg_classical_drop:.2f}%\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Deep Learning models are MORE robust to noise!\")\n",
        "        print(f\"   - Deep Learning avg drop: {avg_dl_drop:.2f}%\")\n",
        "        print(f\"   - Classical avg drop: {avg_classical_drop:.2f}%\")\n",
        "\n",
        "# Frozen vs Fine-tuned comparison\n",
        "frozen_models = [k for k in all_results.keys() if \"Frozen\" in k]\n",
        "finetuned_models = [k for k in all_results.keys() if \"Fine-Tuned\" in k]\n",
        "\n",
        "if frozen_models and finetuned_models:\n",
        "    frozen_drops = [all_results[m][0] - all_results[m][-1] for m in frozen_models]\n",
        "    finetuned_drops = [all_results[m][0] - all_results[m][-1] for m in finetuned_models]\n",
        "\n",
        "    print(f\"\\n‚ùÑÔ∏è Frozen vs üî• Fine-Tuned ConvNeXt:\")\n",
        "    print(f\"   - Frozen avg drop: {np.mean(frozen_drops):.2f}%\")\n",
        "    print(f\"   - Fine-Tuned avg drop: {np.mean(finetuned_drops):.2f}%\")\n",
        "\n",
        "    if np.mean(frozen_drops) < np.mean(finetuned_drops):\n",
        "        print(f\"   ‚úÖ Frozen models are MORE robust (but lower peak accuracy)\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Fine-Tuned models are MORE robust\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ COMBINED ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "_TiprT9qSQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# --- Configuration ---\n",
        "# EXACT Sigma values from your Demo/Report\n",
        "NOISE_LEVELS_FOR_VIS = [0.0, 0.2, 0.4]\n",
        "CLASS_TO_VISUALIZE = 'AnnualCrop'  # Change to 'Forest', 'River', etc. if desired\n",
        "\n",
        "# --- Locate Validation Images ---\n",
        "# Tries to find the specific class folder in the validation set\n",
        "val_class_dir = os.path.join(VAL_DIR, CLASS_TO_VISUALIZE)\n",
        "if not os.path.exists(val_class_dir):\n",
        "    # Fallback: Find the class in the source directory if val doesn't exist separately\n",
        "    print(f\"‚ö†Ô∏è Note: '{CLASS_TO_VISUALIZE}' not found in VAL_DIR. Searching in data root...\")\n",
        "    extracted_root = os.path.join(DATA_DIR, [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d)) and d != 'train' and d != 'val'][0])\n",
        "    val_class_dir = os.path.join(extracted_root, CLASS_TO_VISUALIZE)\n",
        "\n",
        "# 1. Pick a random image\n",
        "image_files = [f for f in os.listdir(val_class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "random_image_file = random.choice(image_files)\n",
        "image_path = os.path.join(val_class_dir, random_image_file)\n",
        "\n",
        "# 2. Define Transform (Resize only, No Normalization yet)\n",
        "# We want to visualize the actual pixels, so we don't normalize to ImageNet stats here.\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load Image\n",
        "original_img_tensor = img_transform(Image.open(image_path))\n",
        "\n",
        "# 3. Noise Function\n",
        "def get_noisy_image(img_tensor, sigma):\n",
        "    \"\"\"Adds Gaussian noise and prepares for plotting.\"\"\"\n",
        "    if sigma == 0.0:\n",
        "        noisy_tensor = img_tensor\n",
        "    else:\n",
        "        # Add additive Gaussian noise\n",
        "        noise = torch.randn_like(img_tensor) * sigma\n",
        "        noisy_tensor = img_tensor + noise\n",
        "\n",
        "    # Clip to valid pixel range [0, 1]\n",
        "    noisy_tensor = torch.clamp(noisy_tensor, 0.0, 1.0)\n",
        "\n",
        "    # Convert to Numpy (Height, Width, Channel) for Matplotlib\n",
        "    img_np = noisy_tensor.permute(1, 2, 0).numpy()\n",
        "    return img_np\n",
        "\n",
        "# 4. Generate Plot\n",
        "fig, axes = plt.subplots(1, len(NOISE_LEVELS_FOR_VIS), figsize=(12, 5))\n",
        "fig.suptitle(f'Effect of Sensor Noise on {CLASS_TO_VISUALIZE} (EuroSAT)', fontsize=14, fontweight='bold')\n",
        "\n",
        "for i, sigma in enumerate(NOISE_LEVELS_FOR_VIS):\n",
        "    noisy_img = get_noisy_image(original_img_tensor, sigma)\n",
        "\n",
        "    # Label matching your report terms\n",
        "    if sigma == 0.0:\n",
        "        label = f\"Clean (œÉ={sigma})\"\n",
        "    elif sigma == 0.2:\n",
        "        label = f\"Low Noise (œÉ={sigma})\"\n",
        "    else:\n",
        "        label = f\"High Noise (œÉ={sigma})\"\n",
        "\n",
        "    axes[i].imshow(noisy_img)\n",
        "    axes[i].set_title(label, fontsize=12)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "print(f\"üì∏ Generating visualization for: {random_image_file}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBNT3UvtCF5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bdnv5mhhCITE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}